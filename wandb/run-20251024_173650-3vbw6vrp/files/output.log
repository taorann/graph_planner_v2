hydra:
  searchpath:
  - pkg://verl.trainer.config
defaults:
- ppo_trainer
- _self_
actor_rollout_ref:
  rollout:
    mode: async
    agent:
      num_workers: 2
    val_kwargs:
      do_sample: true
    temperature: 0.2
    top_p: 0.95
    tensor_model_parallel_size: 2
    'n': 1
    max_prompt_length: 4096
    max_response_length: 512
  model:
    path: /map-vepfs/taoran/graph_planner/models/Qwen3-14B
    tokenizer_path: /map-vepfs/taoran/graph_planner/models/Qwen3-14B
data:
  gen_batch_size: ${mul:${data.train_batch_size},${rllm.rejection_sample.multiplier}}
  train_files: /map-vepfs/taoran/graph_planner/rllm/rllm/data/datasets/graph_planner_repoenv_eval/test_verl.parquet
  val_files: /map-vepfs/taoran/graph_planner/rllm/rllm/data/datasets/graph_planner_repoenv_eval/test_verl.parquet
  train_batch_size: 4
  val_batch_size: 4
  shuffle: false
  max_prompt_length: 4096
  max_response_length: 512
rllm:
  agent:
    name: graph_planner_repoenv
    max_steps: 20
    trajectory_timeout: null
    overlong_filter: false
    agent_args: {}
    engine_args:
      n_parallel_agents: 2
      max_workers: 64
  env:
    name: graph_planner_repoenv
    env_args: {}
  workflow:
    use_workflow: false
    name: single_turn_workflow
    workflow_args:
      agent_cls: null
      agent_args: {}
      env_cls: null
      env_args: {}
      timeout: 1000000.0
      gamma: 0.0
      reward_bonus_coeff: 0.0
    n_parallel_tasks: 2
    retry_limit: 3
  disable_thinking: false
  accumulate_reasoning: false
  mask_truncated_samples: false
  stepwise_advantage:
    enable: false
    mode: broadcast
    normalize_by_steps: false
  compact_filtering:
    enable: false
    mask_max_prompt_length_exceeded: true
    mask_max_response_length_exceeded: true
    mask_env_done: false
    mask_max_turns_exceeded: true
    mask_timeout: true
    mask_unknown: false
    mask_error: true
  rejection_sample:
    enable: false
    multiplier: 1
fireworks:
  deployment_id: null
  model_id_prefix: test-model
  concurrency: 32
trainer:
  project_name: graph-planner
  experiment_name: test4g
  n_gpus_per_node: 4
  total_epochs: 0
  total_training_steps: 0
  val_before_train: true
  val_only: true
  test_freq: -1
  save_freq: -1
  output_dir: /map-vepfs/taoran/graph_planner/outputs/test4g
  default_local_dir: /map-vepfs/taoran/graph_planner/outputs/test4g
  nnodes: 1
  logger:
  - console
  - wandb
critic:
  model:
    path: /map-vepfs/taoran/graph_planner/models/Qwen3-14B
    tokenizer_path: /map-vepfs/taoran/graph_planner/models/Qwen3-14B
ray_init:
  num_cpus: 16
  num_gpus: 4
agent:
  name: graph_planner_repoenv
  max_steps: 6
env:
  name: graph_planner_repoenv
  env_args:
    max_steps: 6
2025-10-24 17:37:00,430	INFO worker.py:1918 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(pid=1168471)[0m /map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
[36m(pid=1168471)[0m   warnings.warn(
Traceback (most recent call last):
  File "/map-vepfs/taoran/graph_planner/scripts/eval_graphplanner_rllm.py", line 363, in <module>
    main()
  File "/map-vepfs/taoran/graph_planner/scripts/eval_graphplanner_rllm.py", line 353, in main
    trainer.train()
  File "/map-vepfs/taoran/graph_planner/rllm/rllm/trainer/agent_trainer.py", line 80, in train
    ray.get(
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/worker.py", line 2858, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/worker.py", line 958, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): [36mray::TaskRunner.run()[39m (pid=1168471, ip=192.168.0.70, actor_id=a6cd1b09b6e162188152d44d01000000, repr=<rllm.trainer.verl.train_agent_ppo.TaskRunner object at 0x7f0e656051b0>)
  File "/map-vepfs/taoran/graph_planner/rllm/rllm/trainer/verl/train_agent_ppo.py", line 92, in run
    tokenizer = hf_tokenizer(local_path, trust_remote_code=trust_remote_code)
  File "/map-vepfs/taoran/graph_planner/rllm/verl/verl/utils/tokenizer.py", line 60, in hf_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 1078, in from_pretrained
    config = AutoConfig.from_pretrained(
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1329, in from_pretrained
    raise ValueError(
ValueError: Unrecognized model in /map-vepfs/taoran/graph_planner/models/Qwen3-14B. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: aimv2, aimv2_vision_model, albert, align, altclip, apertus, arcee, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, bitnet, blenderbot, blenderbot-small, blip, blip-2, blip_2_qformer, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, cohere2_vision, colpali, colqwen2, conditional_detr, convbert, convnext, convnextv2, cpmant, csm, ctrl, cvt, d_fine, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v2, deepseek_v3, deepseek_vl, deepseek_vl_hybrid, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dia, diffllama, dinat, dinov2, dinov2_with_registers, dinov3_convnext, dinov3_vit, distilbert, doge, donut-swin, dots1, dpr, dpt, efficientformer, efficientloftr, efficientnet, electra, emu3, encodec, encoder-decoder, eomt, ernie, ernie4_5, ernie4_5_moe, ernie_m, esm, evolla, exaone4, falcon, falcon_h1, falcon_mamba, fastspeech2_conformer, fastspeech2_conformer_with_hifigan, flaubert, flava, florence2, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, gemma3n, gemma3n_audio, gemma3n_text, gemma3n_vision, git, glm, glm4, glm4_moe, glm4v, glm4v_moe, glm4v_moe_text, glm4v_text, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gpt_oss, gptj, gptsan-japanese, granite, granite_speech, granitemoe, granitemoehybrid, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hgnet_v2, hiera, hubert, hunyuan_v1_dense, hunyuan_v1_moe, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, internvl, internvl_vision, jamba, janus, jetmoe, jukebox, kosmos-2, kosmos-2.5, kyutai_speech_to_text, layoutlm, layoutlmv2, layoutlmv3, led, levit, lfm2, lightglue, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, metaclip_2, mgp-str, mimi, minimax, mistral, mistral3, mixtral, mlcd, mllama, mm-grounding-dino, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, modernbert-decoder, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, ovis2, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, perception_encoder, perception_lm, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_omni, qwen2_5_vl, qwen2_5_vl_text, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen2_vl_text, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam2, sam2_hiera_det_model, sam2_video, sam2_vision_model, sam_hq, sam_hq_vision_model, sam_vision_model, seamless_m4t, seamless_m4t_v2, seed_oss, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smollm3, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, t5gemma, table-transformer, tapas, textnet, time_series_transformer, timesfm, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, uni
Traceback (most recent call last):
  File "/map-vepfs/taoran/graph_planner/scripts/eval_graphplanner_rllm.py", line 363, in <module>
    main()
  File "/map-vepfs/taoran/graph_planner/scripts/eval_graphplanner_rllm.py", line 353, in main
    trainer.train()
  File "/map-vepfs/taoran/graph_planner/rllm/rllm/trainer/agent_trainer.py", line 80, in train
    ray.get(
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/worker.py", line 2858, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/worker.py", line 958, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): [36mray::TaskRunner.run()[39m (pid=1168471, ip=192.168.0.70, actor_id=a6cd1b09b6e162188152d44d01000000, repr=<rllm.trainer.verl.train_agent_ppo.TaskRunner object at 0x7f0e656051b0>)
  File "/map-vepfs/taoran/graph_planner/rllm/rllm/trainer/verl/train_agent_ppo.py", line 92, in run
    tokenizer = hf_tokenizer(local_path, trust_remote_code=trust_remote_code)
  File "/map-vepfs/taoran/graph_planner/rllm/verl/verl/utils/tokenizer.py", line 60, in hf_tokenizer
    tokenizer = AutoTokenizer.from_pretrained(name_or_path, **kwargs)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 1078, in from_pretrained
    config = AutoConfig.from_pretrained(
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1329, in from_pretrained
    raise ValueError(
ValueError: Unrecognized model in /map-vepfs/taoran/graph_planner/models/Qwen3-14B. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: aimv2, aimv2_vision_model, albert, align, altclip, apertus, arcee, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, bitnet, blenderbot, blenderbot-small, blip, blip-2, blip_2_qformer, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, cohere2_vision, colpali, colqwen2, conditional_detr, convbert, convnext, convnextv2, cpmant, csm, ctrl, cvt, d_fine, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v2, deepseek_v3, deepseek_vl, deepseek_vl_hybrid, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dia, diffllama, dinat, dinov2, dinov2_with_registers, dinov3_convnext, dinov3_vit, distilbert, doge, donut-swin, dots1, dpr, dpt, efficientformer, efficientloftr, efficientnet, electra, emu3, encodec, encoder-decoder, eomt, ernie, ernie4_5, ernie4_5_moe, ernie_m, esm, evolla, exaone4, falcon, falcon_h1, falcon_mamba, fastspeech2_conformer, fastspeech2_conformer_with_hifigan, flaubert, flava, florence2, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, gemma3n, gemma3n_audio, gemma3n_text, gemma3n_vision, git, glm, glm4, glm4_moe, glm4v, glm4v_moe, glm4v_moe_text, glm4v_text, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gpt_oss, gptj, gptsan-japanese, granite, granite_speech, granitemoe, granitemoehybrid, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hgnet_v2, hiera, hubert, hunyuan_v1_dense, hunyuan_v1_moe, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, internvl, internvl_vision, jamba, janus, jetmoe, jukebox, kosmos-2, kosmos-2.5, kyutai_speech_to_text, layoutlm, layoutlmv2, layoutlmv3, led, levit, lfm2, lightglue, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, metaclip_2, mgp-str, mimi, minimax, mistral, mistral3, mixtral, mlcd, mllama, mm-grounding-dino, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, modernbert-decoder, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, ovis2, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, perception_encoder, perception_lm, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_omni, qwen2_5_vl, qwen2_5_vl_text, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen2_vl_text, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam2, sam2_hiera_det_model, sam2_video, sam2_vision_model, sam_hq, sam_hq_vision_model, sam_vision_model, seamless_m4t, seamless_m4t_v2, seed_oss, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smollm3, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, t5gemma, table-transformer, tapas, textnet, time_series_transformer, timesfm, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, uni

[36m(TaskRunner pid=1168471)[0m TaskRunner hostname: di-20250214115134-466rr, PID: 1168471
[36m(TaskRunner pid=1168471)[0m {'actor_rollout_ref': {'model': {'path': '/map-vepfs/taoran/graph_planner/models/Qwen3-14B',
[36m(TaskRunner pid=1168471)[0m                                  'tokenizer_path': '/map-vepfs/taoran/graph_planner/models/Qwen3-14B'},
[36m(TaskRunner pid=1168471)[0m                        'rollout': {'agent': {'num_workers': 2},
[36m(TaskRunner pid=1168471)[0m                                    'max_prompt_length': 4096,
[36m(TaskRunner pid=1168471)[0m                                    'max_response_length': 512,
[36m(TaskRunner pid=1168471)[0m                                    'mode': 'async',
[36m(TaskRunner pid=1168471)[0m                                    'n': 1,
[36m(TaskRunner pid=1168471)[0m                                    'temperature': 0.2,
[36m(TaskRunner pid=1168471)[0m                                    'tensor_model_parallel_size': 2,
[36m(TaskRunner pid=1168471)[0m                                    'top_p': 0.95,
[36m(TaskRunner pid=1168471)[0m                                    'val_kwargs': {'do_sample': True}}},
[36m(TaskRunner pid=1168471)[0m  'agent': {'max_steps': 6, 'name': 'graph_planner_repoenv'},
[36m(TaskRunner pid=1168471)[0m  'critic': {'model': {'path': '/map-vepfs/taoran/graph_planner/models/Qwen3-14B',
[36m(TaskRunner pid=1168471)[0m                       'tokenizer_path': '/map-vepfs/taoran/graph_planner/models/Qwen3-14B'}},
[36m(TaskRunner pid=1168471)[0m  'data': {'gen_batch_size': 4,
[36m(TaskRunner pid=1168471)[0m           'max_prompt_length': 4096,
[36m(TaskRunner pid=1168471)[0m           'max_response_length': 512,
[36m(TaskRunner pid=1168471)[0m           'shuffle': False,
[36m(TaskRunner pid=1168471)[0m           'train_batch_size': 4,
[36m(TaskRunner pid=1168471)[0m           'train_files': '/map-vepfs/taoran/graph_planner/rllm/rllm/data/datasets/graph_planner_repoenv_eval/test_verl.parquet',
[36m(TaskRunner pid=1168471)[0m           'val_batch_size': 4,
[36m(TaskRunner pid=1168471)[0m           'val_files': '/map-vepfs/taoran/graph_planner/rllm/rllm/data/datasets/graph_planner_repoenv_eval/test_verl.parquet'},
[36m(TaskRunner pid=1168471)[0m  'defaults': ['ppo_trainer', '_self_'],
[36m(TaskRunner pid=1168471)[0m  'env': {'env_args': {'max_steps': 6}, 'name': 'graph_planner_repoenv'},
[36m(TaskRunner pid=1168471)[0m  'fireworks': {'concurrency': 32,
[36m(TaskRunner pid=1168471)[0m                'deployment_id': None,
[36m(TaskRunner pid=1168471)[0m                'model_id_prefix': 'test-model'},
[36m(TaskRunner pid=1168471)[0m  'hydra': {'searchpath': ['pkg://verl.trainer.config']},
[36m(TaskRunner pid=1168471)[0m  'ray_init': {'num_cpus': 16, 'num_gpus': 4},
[36m(TaskRunner pid=1168471)[0m  'rllm': {'accumulate_reasoning': False,
[36m(TaskRunner pid=1168471)[0m           'agent': {'agent_args': {},
[36m(TaskRunner pid=1168471)[0m                     'engine_args': {'max_workers': 64, 'n_parallel_agents': 2},
[36m(TaskRunner pid=1168471)[0m                     'max_steps': 20,
[36m(TaskRunner pid=1168471)[0m                     'name': 'graph_planner_repoenv',
[36m(TaskRunner pid=1168471)[0m                     'overlong_filter': False,
[36m(TaskRunner pid=1168471)[0m                     'trajectory_timeout': None},
[36m(TaskRunner pid=1168471)[0m           'compact_filtering': {'enable': False,
[36m(TaskRunner pid=1168471)[0m                                 'mask_env_done': False,
[36m(TaskRunner pid=1168471)[0m                                 'mask_error': True,
[36m(TaskRunner pid=1168471)[0m                                 'mask_max_prompt_length_exceeded': True,
[36m(TaskRunner pid=1168471)[0m                                 'mask_max_response_length_exceeded': True,
[36m(TaskRunner pid=1168471)[0m                                 'mask_max_turns_exceeded': True,
[36m(TaskRunner pid=1168471)[0m                                 'mask_timeout': True,
[36m(TaskRunner pid=1168471)[0m                                 'mask_unknown': False},
[36m(TaskRunner pid=1168471)[0m           'disable_thinking': False,
[36m(TaskRunner pid=1168471)[0m           'env': {'env_args': {}, 'name': 'graph_planner_repoenv'},
[36m(TaskRunner pid=1168471)[0m           'mask_truncated_samples': False,
[36m(TaskRunner pid=1168471)[0m           'rejection_sample': {'enable': False, 'multiplier': 1},
[36m(TaskRunner pid=1168471)[0m           'stepwise_advantage': {'enable': False,
[36m(TaskRunner pid=1168471)[0m                                  'mode': 'broadcast',
[36m(TaskRunner pid=1168471)[0m                                  'normalize_by_steps': False},
[36m(TaskRunner pid=1168471)[0m           'workflow': {'n_parallel_tasks': 2,
[36m(TaskRunner pid=1168471)[0m                        'name': 'single_turn_workflow',
[36m(TaskRunner pid=1168471)[0m                        'retry_limit': 3,
[36m(TaskRunner pid=1168471)[0m                        'use_workflow': False,
[36m(TaskRunner pid=1168471)[0m                        'workflow_args': {'agent_args': {},
[36m(TaskRunner pid=1168471)[0m                                          'agent_cls': None,
[36m(TaskRunner pid=1168471)[0m                                          'env_args': {},
[36m(TaskRunner pid=1168471)[0m                                          'env_cls': None,
[36m(TaskRunner pid=1168471)[0m                                          'gamma': 0.0,
[36m(TaskRunner pid=1168471)[0m                                          'reward_bonus_coeff': 0.0,
[36m(TaskRunner pid=1168471)[0m                                          'timeout': 1000000.0}}},
[36m(TaskRunner pid=1168471)[0m  'trainer': {'default_local_dir': '/map-vepfs/taoran/graph_planner/outputs/test4g',
[36m(TaskRunner pid=1168471)[0m              'experiment_name': 'test4g',
[36m(TaskRunner pid=1168471)[0m              'logger': ['console', 'wandb'],
[36m(TaskRunner pid=1168471)[0m              'n_gpus_per_node': 4,
[36m(TaskRunner pid=1168471)[0m              'nnodes': 1,
[36m(TaskRunner pid=1168471)[0m              'output_dir': '/map-vepfs/taoran/graph_planner/outputs/test4g',
[36m(TaskRunner pid=1168471)[0m              'project_name': 'graph-planner',
[36m(TaskRunner pid=1168471)[0m              'save_freq': -1,
[36m(TaskRunner pid=1168471)[0m              'test_freq': -1,
[36m(TaskRunner pid=1168471)[0m              'total_epochs': 0,
[36m(TaskRunner pid=1168471)[0m              'total_training_steps': 0,
[36m(TaskRunner pid=1168471)[0m              'val_before_train': True,
[36m(TaskRunner pid=1168471)[0m              'val_only': True}}
