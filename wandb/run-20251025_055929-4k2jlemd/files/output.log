actor_rollout_ref:
  actor:
    strategy: fsdp
    ppo_mini_batch_size: 256
    ppo_micro_batch_size: null
    ppo_micro_batch_size_per_gpu: null
    use_dynamic_bsz: false
    ppo_max_token_len_per_gpu: 16384
    clip_ratio: 0.2
    clip_ratio_low: 0.2
    clip_ratio_high: 0.2
    policy_loss:
      loss_mode: vanilla
      clip_cov_ratio: 0.0002
      clip_cov_lb: 1.0
      clip_cov_ub: 5.0
      kl_cov_ratio: 0.0002
      ppo_kl_coef: 0.1
    clip_ratio_c: 3.0
    loss_agg_mode: token-mean
    entropy_coeff: 0
    use_kl_loss: false
    use_torch_compile: true
    kl_loss_coef: 0.001
    kl_loss_type: low_var_kl
    ppo_epochs: 1
    shuffle: false
    checkpoint:
      save_contents:
      - model
      - optimizer
      - extra
      load_contents: ${.save_contents}
    optim:
      lr: 1.0e-06
      lr_warmup_steps_ratio: 0.0
      total_training_steps: -1
      weight_decay: 0.01
      lr_warmup_steps: -1
      min_lr_ratio: 0.0
      num_cycles: 0.5
      warmup_style: constant
    grad_clip: 1.0
    ulysses_sequence_parallel_size: 1
    entropy_from_logits_with_chunking: false
    entropy_checkpointing: false
    fsdp_config:
      wrap_policy:
        min_num_params: 0
      param_offload: false
      optimizer_offload: false
      offload_policy: false
      reshard_after_forward: true
      fsdp_size: -1
      forward_prefetch: false
  ref:
    strategy: ${actor_rollout_ref.actor.strategy}
    use_torch_compile: ${oc.select:actor_rollout_ref.actor.use_torch_compile,true}
    log_prob_micro_batch_size: null
    log_prob_micro_batch_size_per_gpu: null
    log_prob_use_dynamic_bsz: ${oc.select:actor_rollout_ref.actor.use_dynamic_bsz,false}
    log_prob_max_token_len_per_gpu: ${oc.select:actor_rollout_ref.actor.ppo_max_token_len_per_gpu,16384}
    fsdp_config:
      param_offload: false
      reshard_after_forward: true
      forward_prefetch: false
      wrap_policy:
        min_num_params: 0
    ulysses_sequence_parallel_size: ${oc.select:actor_rollout_ref.actor.ulysses_sequence_parallel_size,1}
    entropy_from_logits_with_chunking: false
    entropy_checkpointing: false
  rollout:
    name: vllm
    mode: async
    temperature: 0.2
    top_k: -1
    top_p: 0.95
    prompt_length: ${oc.select:data.max_prompt_length,512}
    response_length: ${oc.select:data.max_response_length,512}
    dtype: bfloat16
    gpu_memory_utilization: 0.5
    ignore_eos: false
    enforce_eager: true
    free_cache_engine: true
    tensor_model_parallel_size: 2
    max_num_batched_tokens: 8192
    max_model_len: null
    max_num_seqs: 1024
    log_prob_micro_batch_size: null
    log_prob_micro_batch_size_per_gpu: null
    log_prob_use_dynamic_bsz: ${oc.select:actor_rollout_ref.actor.use_dynamic_bsz,false}
    log_prob_max_token_len_per_gpu: ${oc.select:actor_rollout_ref.actor.ppo_max_token_len_per_gpu,16384}
    disable_log_stats: true
    do_sample: true
    'n': 1
    multi_stage_wake_up: false
    engine_kwargs:
      vllm:
        swap_space: null
        disable_mm_preprocessor_cache: false
      sglang:
        attention_backend: null
    val_kwargs:
      top_k: -1
      top_p: 1.0
      temperature: 0
      'n': 1
      do_sample: true
    multi_turn:
      enable: false
      max_assistant_turns: null
      tool_config_path: null
      max_user_turns: null
      max_parallel_calls: 1
      max_tool_response_length: 256
      tool_response_truncate_side: middle
      interaction_config_path: null
      completion_callback: null
      use_inference_chat_template: false
      tokenization_sanity_check_mode: strict
      format: hermes
    calculate_log_probs: false
    agent:
      num_workers: 2
      agent_loop_config_path: null
      custom_async_server:
        path: null
        name: null
    update_weights_bucket_megabytes: 512
    trace:
      backend: null
      token2text: false
    enable_chunked_prefill: true
    load_format: dummy_dtensor
    layered_summon: false
    max_prompt_length: 4096
    max_response_length: 512
  hybrid_engine: true
  model:
    path: /map-vepfs/taoran/graph_planner/models/qwen3-14b
    custom_chat_template: null
    use_shm: false
    external_lib: null
    override_config: {}
    enable_gradient_checkpointing: true
    enable_activation_offload: false
    use_remove_padding: false
    lora_rank: 0
    lora_alpha: 16
    target_modules: all-linear
    exclude_modules: null
    use_liger: false
    use_fused_kernels: false
    fused_kernel_options:
      impl_backend: torch
    trust_remote_code: false
    tokenizer_path: /map-vepfs/taoran/graph_planner/models/qwen3-14b
  profiler:
    _target_: verl.utils.profiler.ProfilerConfig
    discrete: false
    all_ranks: false
    ranks: []
trainer:
  npu_profile:
    options:
      save_path: ./profiler_data
      level: level1
      with_memory: false
      record_shapes: false
      with_npu: true
      with_cpu: true
      with_module: false
      with_stack: false
      analysis: true
  balance_batch: true
  total_epochs: 0
  total_training_steps: 0
  profile_steps: null
  controller_nsight_options:
    trace: cuda,nvtx,cublas,ucx
    cuda-memory-usage: 'true'
    cuda-graph-trace: graph
  worker_nsight_options:
    trace: cuda,nvtx,cublas,ucx
    cuda-memory-usage: 'true'
    cuda-graph-trace: graph
    capture-range: cudaProfilerApi
    capture-range-end: null
    kill: none
  project_name: graph-planner
  experiment_name: test4g
  logger:
  - console
  - wandb
  log_val_generations: 0
  rollout_data_dir: null
  validation_data_dir: null
  nnodes: 1
  n_gpus_per_node: 4
  save_freq: -1
  esi_redundant_time: 0
  resume_mode: auto
  resume_from_path: null
  val_before_train: true
  val_only: true
  test_freq: -1
  critic_warmup: 0
  default_hdfs_dir: null
  del_local_ckpt_after_load: false
  default_local_dir: /map-vepfs/taoran/graph_planner/outputs/test4g
  max_actor_ckpt_to_keep: null
  max_critic_ckpt_to_keep: null
  ray_wait_register_center_timeout: 300
  device: cuda
  use_legacy_worker_impl: auto
  output_dir: /map-vepfs/taoran/graph_planner/outputs/test4g
data:
  tokenizer: null
  use_shm: false
  train_files: /map-vepfs/taoran/graph_planner/rllm/rllm/data/datasets/graph_planner_repoenv_eval/test_verl.parquet
  val_files: /map-vepfs/taoran/graph_planner/rllm/rllm/data/datasets/graph_planner_repoenv_eval/test_verl.parquet
  prompt_key: prompt
  reward_fn_key: data_source
  max_prompt_length: 4096
  max_response_length: 512
  train_batch_size: 4
  val_batch_size: 4
  return_raw_input_ids: false
  return_raw_chat: false
  return_full_prompt: false
  shuffle: false
  dataloader_num_workers: 8
  validation_shuffle: false
  filter_overlong_prompts: false
  filter_overlong_prompts_workers: 1
  truncation: error
  image_key: images
  video_key: videos
  trust_remote_code: false
  custom_cls:
    path: null
    name: null
  return_multi_modal_inputs: true
  sampler:
    class_path: null
    class_name: null
  datagen:
    path: null
    name: null
  gen_batch_size: ${mul:${data.train_batch_size},${rllm.rejection_sample.multiplier}}
critic:
  rollout_n: ${oc.select:actor_rollout_ref.rollout.n,1}
  strategy: fsdp
  optim:
    lr_warmup_steps_ratio: 0.0
    total_training_steps: -1
    weight_decay: 0.01
    lr: 1.0e-05
    min_lr_ratio: null
    warmup_style: constant
  model:
    path: /map-vepfs/taoran/graph_planner/models/qwen3-14b
    tokenizer_path: /map-vepfs/taoran/graph_planner/models/qwen3-14b
    override_config: {}
    external_lib: ${oc.select:actor_rollout_ref.model.external_lib,null}
    trust_remote_code: ${oc.select:actor_rollout_ref.model.trust_remote_code,false}
    use_shm: false
    enable_gradient_checkpointing: true
    enable_activation_offload: false
    use_remove_padding: false
    fsdp_config:
      param_offload: false
      optimizer_offload: false
      offload_policy: false
      reshard_after_forward: true
      wrap_policy:
        min_num_params: 0
      fsdp_size: -1
      forward_prefetch: false
    lora_rank: 0
    lora_alpha: 16
    target_modules: all-linear
  ppo_mini_batch_size: ${oc.select:actor_rollout_ref.actor.ppo_mini_batch_size,256}
  ppo_micro_batch_size: null
  ppo_micro_batch_size_per_gpu: ${oc.select:.ppo_micro_batch_size,null}
  use_dynamic_bsz: ${oc.select:actor_rollout_ref.actor.use_dynamic_bsz,false}
  ppo_max_token_len_per_gpu: 32768
  forward_max_token_len_per_gpu: ${.ppo_max_token_len_per_gpu}
  ppo_epochs: ${oc.select:actor_rollout_ref.actor.ppo_epochs,1}
  shuffle: ${oc.select:actor_rollout_ref.actor.shuffle,false}
  cliprange_value: 0.5
  loss_agg_mode: ${oc.select:actor_rollout_ref.actor.loss_agg_mode,token-mean}
  checkpoint:
    save_contents:
    - model
    - optimizer
    - extra
    load_contents: ${.save_contents}
  profiler:
    _target_: verl.utils.profiler.ProfilerConfig
    discrete: false
    all_ranks: false
    ranks: []
  _target_: verl.trainer.config.FSDPCriticConfig
  forward_micro_batch_size: ${oc.select:.ppo_micro_batch_size,null}
  forward_micro_batch_size_per_gpu: ${oc.select:.ppo_micro_batch_size_per_gpu,null}
  ulysses_sequence_parallel_size: 1
  grad_clip: 1.0
reward_model:
  enable: false
  strategy: fsdp
  model:
    input_tokenizer: ${actor_rollout_ref.model.path}
    path: ~/models/FsfairX-LLaMA3-RM-v0.1
    external_lib: ${actor_rollout_ref.model.external_lib}
    trust_remote_code: false
    use_shm: false
    use_remove_padding: false
    use_fused_kernels: ${actor_rollout_ref.model.use_fused_kernels}
    fsdp_config:
      wrap_policy:
        min_num_params: 0
      param_offload: false
      reshard_after_forward: true
      fsdp_size: -1
      forward_prefetch: false
  micro_batch_size: null
  micro_batch_size_per_gpu: null
  max_length: null
  use_dynamic_bsz: ${critic.use_dynamic_bsz}
  forward_max_token_len_per_gpu: ${critic.forward_max_token_len_per_gpu}
  reward_manager: naive
  launch_reward_fn_async: false
  sandbox_fusion:
    url: null
    max_concurrent: 64
    memory_limit_mb: 1024
  profiler:
    _target_: verl.utils.profiler.ProfilerConfig
    discrete: false
    all_ranks: false
    ranks: []
  ulysses_sequence_parallel_size: 1
custom_reward_function:
  path: null
  name: compute_score
algorithm:
  _target_: verl.trainer.config.AlgoConfig
  gamma: 1.0
  lam: 1.0
  adv_estimator: gae
  norm_adv_by_std_in_grpo: true
  use_kl_in_reward: false
  kl_penalty: kl
  kl_ctrl:
    _target_: verl.trainer.config.KLControlConfig
    type: fixed
    kl_coef: 0.001
    horizon: 10000
    target_kl: 0.1
  use_pf_ppo: false
  pf_ppo:
    _target_: verl.trainer.config.PFPPOConfig
    reweight_method: pow
    weight_pow: 2.0
ray_init:
  num_cpus: 16
  timeline_json_file: null
  num_gpus: 4
rllm:
  agent:
    name: graph_planner_repoenv
    max_steps: 20
    trajectory_timeout: null
    overlong_filter: false
    agent_args: {}
    engine_args:
      n_parallel_agents: 2
      max_workers: 64
  env:
    name: graph_planner_repoenv
    env_args: {}
  workflow:
    use_workflow: false
    name: single_turn_workflow
    workflow_args:
      agent_cls: null
      agent_args: {}
      env_cls: null
      env_args: {}
      timeout: 1000000.0
      gamma: 0.0
      reward_bonus_coeff: 0.0
    n_parallel_tasks: 2
    retry_limit: 3
  disable_thinking: false
  accumulate_reasoning: false
  mask_truncated_samples: false
  stepwise_advantage:
    enable: false
    mode: broadcast
    normalize_by_steps: false
  compact_filtering:
    enable: false
    mask_max_prompt_length_exceeded: true
    mask_max_response_length_exceeded: true
    mask_env_done: false
    mask_max_turns_exceeded: true
    mask_timeout: true
    mask_unknown: false
    mask_error: true
  rejection_sample:
    enable: false
    multiplier: 1
fireworks:
  deployment_id: null
  model_id_prefix: test-model
  concurrency: 32
agent:
  name: graph_planner_repoenv
  max_steps: 6
env:
  name: graph_planner_repoenv
  env_args:
    max_steps: 6
2025-10-25 05:59:42,528	INFO worker.py:1918 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
[36m(pid=1680586)[0m /map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
[36m(pid=1680586)[0m   warnings.warn(

[36m(TaskRunner pid=1680586)[0m TaskRunner hostname: di-20250214115134-466rr, PID: 1680586
[36m(TaskRunner pid=1680586)[0m {'actor_rollout_ref': {'actor': {'checkpoint': {'load_contents': ['model',
[36m(TaskRunner pid=1680586)[0m                                                                   'optimizer',
[36m(TaskRunner pid=1680586)[0m                                                                   'extra'],
[36m(TaskRunner pid=1680586)[0m                                                 'save_contents': ['model',
[36m(TaskRunner pid=1680586)[0m                                                                   'optimizer',
[36m(TaskRunner pid=1680586)[0m                                                                   'extra']},
[36m(TaskRunner pid=1680586)[0m                                  'clip_ratio': 0.2,
[36m(TaskRunner pid=1680586)[0m                                  'clip_ratio_c': 3.0,
[36m(TaskRunner pid=1680586)[0m                                  'clip_ratio_high': 0.2,
[36m(TaskRunner pid=1680586)[0m                                  'clip_ratio_low': 0.2,
[36m(TaskRunner pid=1680586)[0m                                  'entropy_checkpointing': False,
[36m(TaskRunner pid=1680586)[0m                                  'entropy_coeff': 0,
[36m(TaskRunner pid=1680586)[0m                                  'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=1680586)[0m                                  'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1680586)[0m                                                  'fsdp_size': -1,
[36m(TaskRunner pid=1680586)[0m                                                  'offload_policy': False,
[36m(TaskRunner pid=1680586)[0m                                                  'optimizer_offload': False,
[36m(TaskRunner pid=1680586)[0m                                                  'param_offload': False,
[36m(TaskRunner pid=1680586)[0m                                                  'reshard_after_forward': True,
[36m(TaskRunner pid=1680586)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1680586)[0m                                  'grad_clip': 1.0,
[36m(TaskRunner pid=1680586)[0m                                  'kl_loss_coef': 0.001,
[36m(TaskRunner pid=1680586)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(TaskRunner pid=1680586)[0m                                  'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=1680586)[0m                                  'optim': {'lr': 1e-06,
[36m(TaskRunner pid=1680586)[0m                                            'lr_warmup_steps': -1,
[36m(TaskRunner pid=1680586)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=1680586)[0m                                            'min_lr_ratio': 0.0,
[36m(TaskRunner pid=1680586)[0m                                            'num_cycles': 0.5,
[36m(TaskRunner pid=1680586)[0m                                            'total_training_steps': -1,
[36m(TaskRunner pid=1680586)[0m                                            'warmup_style': 'constant',
[36m(TaskRunner pid=1680586)[0m                                            'weight_decay': 0.01},
[36m(TaskRunner pid=1680586)[0m                                  'policy_loss': {'clip_cov_lb': 1.0,
[36m(TaskRunner pid=1680586)[0m                                                  'clip_cov_ratio': 0.0002,
[36m(TaskRunner pid=1680586)[0m                                                  'clip_cov_ub': 5.0,
[36m(TaskRunner pid=1680586)[0m                                                  'kl_cov_ratio': 0.0002,
[36m(TaskRunner pid=1680586)[0m                                                  'loss_mode': 'vanilla',
[36m(TaskRunner pid=1680586)[0m                                                  'ppo_kl_coef': 0.1},
[36m(TaskRunner pid=1680586)[0m                                  'ppo_epochs': 1,
[36m(TaskRunner pid=1680586)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1680586)[0m                                  'ppo_micro_batch_size': None,
[36m(TaskRunner pid=1680586)[0m                                  'ppo_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1680586)[0m                                  'ppo_mini_batch_size': 256,
[36m(TaskRunner pid=1680586)[0m                                  'shuffle': False,
[36m(TaskRunner pid=1680586)[0m                                  'strategy': 'fsdp',
[36m(TaskRunner pid=1680586)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1680586)[0m                                  'use_dynamic_bsz': False,
[36m(TaskRunner pid=1680586)[0m                                  'use_kl_loss': False,
[36m(TaskRunner pid=1680586)[0m                                  'use_torch_compile': True},
[36m(TaskRunner pid=1680586)[0m                        'hybrid_engine': True,
[36m(TaskRunner pid=1680586)[0m                        'model': {'custom_chat_template': None,
[36m(TaskRunner pid=1680586)[0m                                  'enable_activation_offload': False,
[36m(TaskRunner pid=1680586)[0m                                  'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=1680586)[0m                                  'exclude_modules': None,
[36m(TaskRunner pid=1680586)[0m                                  'external_lib': None,
[36m(TaskRunner pid=1680586)[0m                                  'fused_kernel_options': {'impl_backend': 'torch'},
[36m(TaskRunner pid=1680586)[0m                                  'lora_alpha': 16,
[36m(TaskRunner pid=1680586)[0m                                  'lora_rank': 0,
[36m(TaskRunner pid=1680586)[0m                                  'override_config': {},
[36m(TaskRunner pid=1680586)[0m                                  'path': '/map-vepfs/taoran/graph_planner/models/qwen3-14b',
[36m(TaskRunner pid=1680586)[0m                                  'target_modules': 'all-linear',
[36m(TaskRunner pid=1680586)[0m                                  'tokenizer_path': '/map-vepfs/taoran/graph_planner/models/qwen3-14b',
[36m(TaskRunner pid=1680586)[0m                                  'trust_remote_code': False,
[36m(TaskRunner pid=1680586)[0m                                  'use_fused_kernels': False,
[36m(TaskRunner pid=1680586)[0m                                  'use_liger': False,
[36m(TaskRunner pid=1680586)[0m                                  'use_remove_padding': False,
[36m(TaskRunner pid=1680586)[0m                                  'use_shm': False},
[36m(TaskRunner pid=1680586)[0m                        'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=1680586)[0m                                     'all_ranks': False,
[36m(TaskRunner pid=1680586)[0m                                     'discrete': False,
[36m(TaskRunner pid=1680586)[0m                                     'ranks': []},
[36m(TaskRunner pid=1680586)[0m                        'ref': {'entropy_checkpointing': False,
[36m(TaskRunner pid=1680586)[0m                                'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=1680586)[0m                                'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1680586)[0m                                                'param_offload': False,
[36m(TaskRunner pid=1680586)[0m                                                'reshard_after_forward': True,
[36m(TaskRunner pid=1680586)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1680586)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1680586)[0m                                'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=1680586)[0m                                'log_prob_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1680586)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=1680586)[0m                                'strategy': 'fsdp',
[36m(TaskRunner pid=1680586)[0m                                'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1680586)[0m                                'use_torch_compile': True},
[36m(TaskRunner pid=1680586)[0m                        'rollout': {'agent':
[36m(TaskRunner pid=1680586)[0m {'agent_loop_config_path': None,
[36m(TaskRunner pid=1680586)[0m                                              'custom_async_server': {'name': None,
[36m(TaskRunner pid=1680586)[0m                                                                      'path': None},
[36m(TaskRunner pid=1680586)[0m                                              'num_workers': 2},
[36m(TaskRunner pid=1680586)[0m                                    'calculate_log_probs': False,
[36m(TaskRunner pid=1680586)[0m                                    'disable_log_stats': True,
[36m(TaskRunner pid=1680586)[0m                                    'do_sample': True,
[36m(TaskRunner pid=1680586)[0m                                    'dtype': 'bfloat16',
[36m(TaskRunner pid=1680586)[0m                                    'enable_chunked_prefill': True,
[36m(TaskRunner pid=1680586)[0m                                    'enforce_eager': True,
[36m(TaskRunner pid=1680586)[0m                                    'engine_kwargs': {'sglang': {'attention_backend': None},
[36m(TaskRunner pid=1680586)[0m                                                      'vllm': {'disable_mm_preprocessor_cache': False,
[36m(TaskRunner pid=1680586)[0m                                                               'swap_space': None}},
[36m(TaskRunner pid=1680586)[0m                                    'free_cache_engine': True,
[36m(TaskRunner pid=1680586)[0m                                    'gpu_memory_utilization': 0.5,
[36m(TaskRunner pid=1680586)[0m                                    'ignore_eos': False,
[36m(TaskRunner pid=1680586)[0m                                    'layered_summon': False,
[36m(TaskRunner pid=1680586)[0m                                    'load_format': 'dummy_dtensor',
[36m(TaskRunner pid=1680586)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=1680586)[0m                                    'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=1680586)[0m                                    'log_prob_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1680586)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=1680586)[0m                                    'max_model_len': None,
[36m(TaskRunner pid=1680586)[0m                                    'max_num_batched_tokens': 8192,
[36m(TaskRunner pid=1680586)[0m                                    'max_num_seqs': 1024,
[36m(TaskRunner pid=1680586)[0m                                    'max_prompt_length': 4096,
[36m(TaskRunner pid=1680586)[0m                                    'max_response_length': 512,
[36m(TaskRunner pid=1680586)[0m                                    'mode': 'async',
[36m(TaskRunner pid=1680586)[0m                                    'multi_stage_wake_up': False,
[36m(TaskRunner pid=1680586)[0m                                    'multi_turn': {'completion_callback': None,
[36m(TaskRunner pid=1680586)[0m                                                   'enable': False,
[36m(TaskRunner pid=1680586)[0m                                                   'format': 'hermes',
[36m(TaskRunner pid=1680586)[0m                                                   'interaction_config_path': None,
[36m(TaskRunner pid=1680586)[0m                                                   'max_assistant_turns': None,
[36m(TaskRunner pid=1680586)[0m                                                   'max_parallel_calls': 1,
[36m(TaskRunner pid=1680586)[0m                                                   'max_tool_response_length': 256,
[36m(TaskRunner pid=1680586)[0m                                                   'max_user_turns': None,
[36m(TaskRunner pid=1680586)[0m                                                   'tokenization_sanity_check_mode': 'strict',
[36m(TaskRunner pid=1680586)[0m                                                   'tool_config_path': None,
[36m(TaskRunner pid=1680586)[0m                                                   'tool_response_truncate_side': 'middle',
[36m(TaskRunner pid=1680586)[0m                                                   'use_inference_chat_template': False},
[36m(TaskRunner pid=1680586)[0m                                    'n': 1,
[36m(TaskRunner pid=1680586)[0m                                    'name': 'vllm',
[36m(TaskRunner pid=1680586)[0m                                    'prompt_length': 4096,
[36m(TaskRunner pid=1680586)[0m                                    'response_length': 512,
[36m(TaskRunner pid=1680586)[0m                                    'temperature': 0.2,
[36m(TaskRunner pid=1680586)[0m                                    'tensor_model_parallel_size': 2,
[36m(TaskRunner pid=1680586)[0m                                    'top_k': -1,
[36m(TaskRunner pid=1680586)[0m                                    'top_p': 0.95,
[36m(TaskRunner pid=1680586)[0m                                    'trace': {'backend': None,
[36m(TaskRunner pid=1680586)[0m                                              'token2text': False},
[36m(TaskRunner pid=1680586)[0m                                    'update_weights_bucket_megabytes': 512,
[36m(TaskRunner pid=1680586)[0m                                    'val_kwargs': {'do_sample': True,
[36m(TaskRunner pid=1680586)[0m                                                   'n': 1,
[36m(TaskRunner pid=1680586)[0m                                                   'temperature': 0,
[36m(TaskRunner pid=1680586)[0m                                                   'top_k': -1,
[36m(TaskRunner pid=1680586)[0m                                                   'top_p': 1.0}}},
[36m(TaskRunner pid=1680586)[0m  'agent': {'max_steps': 6, 'name': 'graph_planner_repoenv'},
[36m(TaskRunner pid=1680586)[0m  'algorithm': {'_target_': 'verl.trainer.config.AlgoConfig',
[36m(TaskRunner pid=1680586)[0m                'adv_estimator': 'gae',
[36m(TaskRunner pid=1680586)[0m                'gamma': 1.0,
[36m(TaskRunner pid=1680586)[0m                'kl_ctrl': {'_target_': 'verl.trainer.config.KLControlConfig',
[36m(TaskRunner pid=1680586)[0m                            'horizon': 10000,
[36m(TaskRunner pid=1680586)[0m                            'kl_coef': 0.001,
[36m(TaskRunner pid=1680586)[0m                            'target_kl': 0.1,
[36m(TaskRunner pid=1680586)[0m                            'type': 'fixed'},
[36m(TaskRunner pid=1680586)[0m                'kl_penalty': 'kl',
[36m(TaskRunner pid=1680586)[0m                'lam': 1.0,
[36m(TaskRunner pid=1680586)[0m                'norm_adv_by_std_in_grpo': True,
[36m(TaskRunner pid=1680586)[0m                'pf_ppo': {'_target_': 'verl.trainer.config.PFPPOConfig',
[36m(TaskRunner pid=1680586)[0m                           'reweight_method': 'pow',
[36m(TaskRunner pid=1680586)[0m                           'weight_pow': 2.0},
[36m(TaskRunner pid=1680586)[0m                'use_kl_in_reward': False,
[36m(TaskRunner pid=1680586)[0m                'use_pf_ppo':
[36m(TaskRunner pid=1680586)[0m False
[36m(TaskRunner pid=1680586)[0m },
[36m(TaskRunner pid=1680586)[0m  'critic': {'_target_': 'verl.trainer.config.FSDPCriticConfig',
[36m(TaskRunner pid=1680586)[0m             'checkpoint': {'load_contents': ['model', 'optimizer', 'extra'],
[36m(TaskRunner pid=1680586)[0m                            'save_contents': ['model', 'optimizer', 'extra']},
[36m(TaskRunner pid=1680586)[0m             'cliprange_value': 0.5,
[36m(TaskRunner pid=1680586)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1680586)[0m             'forward_micro_batch_size': None,
[36m(TaskRunner pid=1680586)[0m             'forward_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1680586)[0m             'grad_clip': 1.0,
[36m(TaskRunner pid=1680586)[0m             'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=1680586)[0m             'model': {'enable_activation_offload': False,
[36m(TaskRunner pid=1680586)[0m                       'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=1680586)[0m                       'external_lib': None,
[36m(TaskRunner pid=1680586)[0m                       'fsdp_config': {'forward_prefetch': False,
[36m(TaskRunner pid=1680586)[0m                                       'fsdp_size': -1,
[36m(TaskRunner pid=1680586)[0m                                       'offload_policy': False,
[36m(TaskRunner pid=1680586)[0m                                       'optimizer_offload': False,
[36m(TaskRunner pid=1680586)[0m                                       'param_offload': False,
[36m(TaskRunner pid=1680586)[0m                                       'reshard_after_forward': True,
[36m(TaskRunner pid=1680586)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1680586)[0m                       'lora_alpha': 16,
[36m(TaskRunner pid=1680586)[0m                       'lora_rank': 0,
[36m(TaskRunner pid=1680586)[0m                       'override_config': {},
[36m(TaskRunner pid=1680586)[0m                       'path': '/map-vepfs/taoran/graph_planner/models/qwen3-14b',
[36m(TaskRunner pid=1680586)[0m                       'target_modules': 'all-linear',
[36m(TaskRunner pid=1680586)[0m                       'tokenizer_path': '/map-vepfs/taoran/graph_planner/models/qwen3-14b',
[36m(TaskRunner pid=1680586)[0m                       'trust_remote_code': False,
[36m(TaskRunner pid=1680586)[0m                       'use_remove_padding': False,
[36m(TaskRunner pid=1680586)[0m                       'use_shm': False},
[36m(TaskRunner pid=1680586)[0m             'optim': {'lr': 1e-05,
[36m(TaskRunner pid=1680586)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=1680586)[0m                       'min_lr_ratio': None,
[36m(TaskRunner pid=1680586)[0m                       'total_training_steps': -1,
[36m(TaskRunner pid=1680586)[0m                       'warmup_style': 'constant',
[36m(TaskRunner pid=1680586)[0m                       'weight_decay': 0.01},
[36m(TaskRunner pid=1680586)[0m             'ppo_epochs': 1,
[36m(TaskRunner pid=1680586)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1680586)[0m             'ppo_micro_batch_size': None,
[36m(TaskRunner pid=1680586)[0m             'ppo_micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1680586)[0m             'ppo_mini_batch_size': 256,
[36m(TaskRunner pid=1680586)[0m             'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=1680586)[0m                          'all_ranks': False,
[36m(TaskRunner pid=1680586)[0m                          'discrete': False,
[36m(TaskRunner pid=1680586)[0m                          'ranks': []}
[36m(TaskRunner pid=1680586)[0m ,
[36m(TaskRunner pid=1680586)[0m
[36m(TaskRunner pid=1680586)[0m 'rollout_n': 1,
[36m(TaskRunner pid=1680586)[0m             'shuffle': False,
[36m(TaskRunner pid=1680586)[0m             'strategy': 'fsdp',
[36m(TaskRunner pid=1680586)[0m             'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1680586)[0m             'use_dynamic_bsz': False},
[36m(TaskRunner pid=1680586)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(TaskRunner pid=1680586)[0m  'data': {'custom_cls': {'name': None, 'path': None},
[36m(TaskRunner pid=1680586)[0m           'datagen': {'name': None, 'path': None},
[36m(TaskRunner pid=1680586)[0m           'dataloader_num_workers': 8,
[36m(TaskRunner pid=1680586)[0m           'filter_overlong_prompts': False,
[36m(TaskRunner pid=1680586)[0m           'filter_overlong_prompts_workers': 1,
[36m(TaskRunner pid=1680586)[0m           'gen_batch_size': 4,
[36m(TaskRunner pid=1680586)[0m           'image_key': 'images',
[36m(TaskRunner pid=1680586)[0m           'max_prompt_length': 4096,
[36m(TaskRunner pid=1680586)[0m           'max_response_length': 512,
[36m(TaskRunner pid=1680586)[0m           'prompt_key': 'prompt',
[36m(TaskRunner pid=1680586)[0m           'return_full_prompt': False,
[36m(TaskRunner pid=1680586)[0m           'return_multi_modal_inputs': True,
[36m(TaskRunner pid=1680586)[0m           'return_raw_chat': False,
[36m(TaskRunner pid=1680586)[0m           'return_raw_input_ids': False,
[36m(TaskRunner pid=1680586)[0m           'reward_fn_key': 'data_source',
[36m(TaskRunner pid=1680586)[0m           'sampler': {'class_name': None, 'class_path': None},
[36m(TaskRunner pid=1680586)[0m           'shuffle': False,
[36m(TaskRunner pid=1680586)[0m           'tokenizer': None,
[36m(TaskRunner pid=1680586)[0m           'train_batch_size': 4,
[36m(TaskRunner pid=1680586)[0m           'train_files': '/map-vepfs/taoran/graph_planner/rllm/rllm/data/datasets/graph_planner_repoenv_eval/test_verl.parquet',
[36m(TaskRunner pid=1680586)[0m           'truncation': 'error',
[36m(TaskRunner pid=1680586)[0m           'trust_remote_code': False,
[36m(TaskRunner pid=1680586)[0m           'use_shm': False,
[36m(TaskRunner pid=1680586)[0m           'val_batch_size': 4,
[36m(TaskRunner pid=1680586)[0m           'val_files': '/map-vepfs/taoran/graph_planner/rllm/rllm/data/datasets/graph_planner_repoenv_eval/test_verl.parquet',
[36m(TaskRunner pid=1680586)[0m           'validation_shuffle': False,
[36m(TaskRunner pid=1680586)[0m           'video_key': 'videos'},
[36m(TaskRunner pid=1680586)[0m  'env': {'env_args': {'max_steps': 6}, 'name': 'graph_planner_repoenv'},
[36m(TaskRunner pid=1680586)[0m  'fireworks': {'concurrency': 32,
[36m(TaskRunner pid=1680586)[0m                'deployment_id': None,
[36m(TaskRunner pid=1680586)[0m                'model_id_prefix': 'test-model'},
[36m(TaskRunner pid=1680586)[0m  'ray_init': {'num_cpus': 16, 'num_gpus': 4, 'timeline_json_file': None},
[36m(TaskRunner pid=1680586)[0m  'reward_model': {'enable': False,
[36m(TaskRunner pid=1680586)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=1680586)[0m                   'launch_reward_fn_async': False,
[36m(TaskRunner pid=1680586)[0m                   'max_length': None,
[36m(TaskRunner pid=1680586)[0m                   'micro_batch_size': None,
[36m(TaskRunner pid=1680586)[0m                   'micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=1680586)[0m                   'model': {'external_lib': None,
[36m(TaskRunner pid=1680586)[0m                             'fsdp_config': {'forward_prefetch'
[36m(TaskRunner pid=1680586)[0m :
[36m(TaskRunner pid=1680586)[0m False,
[36m(TaskRunner pid=1680586)[0m                                             'fsdp_size': -1,
[36m(TaskRunner pid=1680586)[0m                                             'param_offload': False,
[36m(TaskRunner pid=1680586)[0m                                             'reshard_after_forward': True,
[36m(TaskRunner pid=1680586)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=1680586)[0m                             'input_tokenizer': '/map-vepfs/taoran/graph_planner/models/qwen3-14b',
[36m(TaskRunner pid=1680586)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(TaskRunner pid=1680586)[0m                             'trust_remote_code': False,
[36m(TaskRunner pid=1680586)[0m                             'use_fused_kernels': False,
[36m(TaskRunner pid=1680586)[0m                             'use_remove_padding': False,
[36m(TaskRunner pid=1680586)[0m                             'use_shm': False},
[36m(TaskRunner pid=1680586)[0m                   'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=1680586)[0m                                'all_ranks': False,
[36m(TaskRunner pid=1680586)[0m                                'discrete': False,
[36m(TaskRunner pid=1680586)[0m                                'ranks': []},
[36m(TaskRunner pid=1680586)[0m                   'reward_manager': 'naive',
[36m(TaskRunner pid=1680586)[0m                   'sandbox_fusion': {'max_concurrent': 64,
[36m(TaskRunner pid=1680586)[0m                                      'memory_limit_mb': 1024,
[36m(TaskRunner pid=1680586)[0m                                      'url': None},
[36m(TaskRunner pid=1680586)[0m                   'strategy': 'fsdp',
[36m(TaskRunner pid=1680586)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=1680586)[0m                   'use_dynamic_bsz': False},
[36m(TaskRunner pid=1680586)[0m  'rllm': {'accumulate_reasoning': False,
[36m(TaskRunner pid=1680586)[0m           'agent': {'agent_args': {},
[36m(TaskRunner pid=1680586)[0m                     'engine_args': {'max_workers': 64, 'n_parallel_agents': 2},
[36m(TaskRunner pid=1680586)[0m                     'max_steps': 20,
[36m(TaskRunner pid=1680586)[0m                     'name': 'graph_planner_repoenv',
[36m(TaskRunner pid=1680586)[0m                     'overlong_filter': False,
[36m(TaskRunner pid=1680586)[0m                     'trajectory_timeout': None},
[36m(TaskRunner pid=1680586)[0m           'compact_filtering': {'enable': False,
[36m(TaskRunner pid=1680586)[0m                                 'mask_env_done': False,
[36m(TaskRunner pid=1680586)[0m                                 'mask_error': True,
[36m(TaskRunner pid=1680586)[0m                                 'mask_max_prompt_length_exceeded': True,
[36m(TaskRunner pid=1680586)[0m                                 'mask_max_response_length_exceeded': True,
[36m(TaskRunner pid=1680586)[0m                                 'mask_max_turns_exceeded': True,
[36m(TaskRunner pid=1680586)[0m                                 'mask_timeout': True,
[36m(TaskRunner pid=1680586)[0m                                 'mask_unknown':
[36m(TaskRunner pid=1680586)[0m False},
[36m(TaskRunner pid=1680586)[0m           'disable_thinking': False,
[36m(TaskRunner pid=1680586)[0m           'env': {'env_args': {}, 'name': 'graph_planner_repoenv'},
[36m(TaskRunner pid=1680586)[0m           'mask_truncated_samples': False,
[36m(TaskRunner pid=1680586)[0m           'rejection_sample': {'enable': False, 'multiplier': 1},
[36m(TaskRunner pid=1680586)[0m           'stepwise_advantage': {'enable': False,
[36m(TaskRunner pid=1680586)[0m                                  'mode': 'broadcast',
[36m(TaskRunner pid=1680586)[0m                                  'normalize_by_steps': False},
[36m(TaskRunner pid=1680586)[0m           'workflow': {'n_parallel_tasks': 2,
[36m(TaskRunner pid=1680586)[0m                        'name': 'single_turn_workflow',
[36m(TaskRunner pid=1680586)[0m                        'retry_limit': 3,
[36m(TaskRunner pid=1680586)[0m                        'use_workflow': False,
[36m(TaskRunner pid=1680586)[0m                        'workflow_args': {'agent_args': {},
[36m(TaskRunner pid=1680586)[0m                                          'agent_cls': None,
[36m(TaskRunner pid=1680586)[0m                                          'env_args': {},
[36m(TaskRunner pid=1680586)[0m                                          'env_cls': None,
[36m(TaskRunner pid=1680586)[0m                                          'gamma': 0.0,
[36m(TaskRunner pid=1680586)[0m                                          'reward_bonus_coeff': 0.0,
[36m(TaskRunner pid=1680586)[0m                                          'timeout': 1000000.0}}},
[36m(TaskRunner pid=1680586)[0m  'trainer': {'balance_batch': True,
[36m(TaskRunner pid=1680586)[0m              'controller_nsight_options': {'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=1680586)[0m                                            'cuda-memory-usage': 'true',
[36m(TaskRunner pid=1680586)[0m                                            'trace': 'cuda,nvtx,cublas,ucx'},
[36m(TaskRunner pid=1680586)[0m              'critic_warmup': 0,
[36m(TaskRunner pid=1680586)[0m              'default_hdfs_dir': None,
[36m(TaskRunner pid=1680586)[0m              'default_local_dir': '/map-vepfs/taoran/graph_planner/outputs/test4g',
[36m(TaskRunner pid=1680586)[0m              'del_local_ckpt_after_load': False,
[36m(TaskRunner pid=1680586)[0m              'device': 'cuda',
[36m(TaskRunner pid=1680586)[0m              'esi_redundant_time': 0,
[36m(TaskRunner pid=1680586)[0m              'experiment_name': 'test4g',
[36m(TaskRunner pid=1680586)[0m              'log_val_generations': 0,
[36m(TaskRunner pid=1680586)[0m              'logger': ['console', 'wandb'],
[36m(TaskRunner pid=1680586)[0m              'max_actor_ckpt_to_keep': None,
[36m(TaskRunner pid=1680586)[0m              'max_critic_ckpt_to_keep': None,
[36m(TaskRunner pid=1680586)[0m              'n_gpus_per_node': 4,
[36m(TaskRunner pid=1680586)[0m              'nnodes': 1,
[36m(TaskRunner pid=1680586)[0m              'npu_profile': {'options': {'analysis': True,
[36m(TaskRunner pid=1680586)[0m                                          'level': 'level1',
[36m(TaskRunner pid=1680586)[0m                                          'record_shapes': False,
[36m(TaskRunner pid=1680586)[0m                                          'save_path': './profiler_data',
[36m(TaskRunner pid=1680586)[0m                                          'with_cpu': True,
[36m(TaskRunner pid=1680586)[0m                                          'with_memory': False,
[36m(TaskRunner pid=1680586)[0m                                          'with_module': False,
[36m(TaskRunner pid=1680586)[0m                                          'with_npu': True,
[36m(TaskRunner pid=1680586)[0m                                          'with_stack': False}},
[36m(TaskRunner pid=1680586)[0m              'output_dir': '/map-vepfs/taoran/graph_planner/outputs/test4g',
[36m(TaskRunner pid=1680586)[0m              'profile_steps': None,
[36m(TaskRunner pid=1680586)[0m              'project_name': 'graph-planner',
[36m(TaskRunner pid=1680586)[0m              'ray_wait_register_center_timeout': 300,
[36m(TaskRunner pid=1680586)[0m              'resume_from_path': None,
[36m(TaskRunner pid=1680586)[0m              'resume_mode': 'auto',
[36m(TaskRunner pid=1680586)[0m              'rollout_data_dir'
[36m(TaskRunner pid=1680586)[0m :
[36m(TaskRunner pid=1680586)[0m None
[36m(TaskRunner pid=1680586)[0m ,
[36m(TaskRunner pid=1680586)[0m
[36m(TaskRunner pid=1680586)[0m 'save_freq'
[36m(TaskRunner pid=1680586)[0m :
[36m(TaskRunner pid=1680586)[0m -1,
[36m(TaskRunner pid=1680586)[0m              'test_freq': -1,
[36m(TaskRunner pid=1680586)[0m              'total_epochs': 0,
[36m(TaskRunner pid=1680586)[0m              'total_training_steps': 0,
[36m(TaskRunner pid=1680586)[0m              'use_legacy_worker_impl': 'auto',
[36m(TaskRunner pid=1680586)[0m              'val_before_train': True,
[36m(TaskRunner pid=1680586)[0m              'val_only': True,
[36m(TaskRunner pid=1680586)[0m              'validation_data_dir': None,
[36m(TaskRunner pid=1680586)[0m              'worker_nsight_options': {'capture-range': 'cudaProfilerApi',
[36m(TaskRunner pid=1680586)[0m                                        'capture-range-end': None,
[36m(TaskRunner pid=1680586)[0m                                        'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=1680586)[0m                                        'cuda-memory-usage': 'true',
[36m(TaskRunner pid=1680586)[0m                                        'kill': 'none',
[36m(TaskRunner pid=1680586)[0m                                        'trace': 'cuda,nvtx,cublas,ucx'}}}
[36m(TaskRunner pid=1680586)[0m WARNING:2025-10-25 05:59:59,399:The 8-bit optimizer is not available on your device, only available on CUDA for now.
Traceback (most recent call last):
  File "/map-vepfs/taoran/graph_planner/scripts/eval_graphplanner_rllm.py", line 363, in <module>
    main()
  File "/map-vepfs/taoran/graph_planner/scripts/eval_graphplanner_rllm.py", line 353, in main
    trainer.train()
  File "/map-vepfs/taoran/graph_planner/rllm/rllm/trainer/agent_trainer.py", line 80, in train
    ray.get(
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/worker.py", line 2858, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/worker.py", line 958, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): [36mray::TaskRunner.run()[39m (pid=1680586, ip=192.168.0.70, actor_id=62d63a2586484fb984c17fe001000000, repr=<rllm.trainer.verl.train_agent_ppo.TaskRunner object at 0x7f15c567b1c0>)
  File "/map-vepfs/taoran/graph_planner/rllm/rllm/trainer/verl/train_agent_ppo.py", line 195, in run
    trainer = AgentPPOTrainer(
  File "/map-vepfs/taoran/graph_planner/rllm/rllm/trainer/verl/agent_ppo_trainer.py", line 50, in __init__
    super().__init__(config=config, tokenizer=tokenizer, role_worker_mapping=role_worker_mapping, resource_pool_manager=resource_pool_manager, ray_worker_group_cls=ray_worker_group_cls, reward_fn=reward_fn, val_reward_fn=val_reward_fn)
  File "/map-vepfs/taoran/graph_planner/rllm/verl/verl/trainer/ppo/ray_trainer.py", line 388, in __init__
    self._validate_config()
  File "/map-vepfs/taoran/graph_planner/rllm/verl/verl/trainer/ppo/ray_trainer.py", line 461, in _validate_config
    check_mutually_exclusive(
  File "/map-vepfs/taoran/graph_planner/rllm/verl/verl/trainer/ppo/ray_trainer.py", line 449, in check_mutually_exclusive
    raise ValueError(
ValueError: [actor_rollout_ref.actor] Please set at least one of 'actor_rollout_ref.actor.micro_batch_size' or 'actor_rollout_ref.actor.micro_batch_size_per_gpu'.
Traceback (most recent call last):
  File "/map-vepfs/taoran/graph_planner/scripts/eval_graphplanner_rllm.py", line 363, in <module>
    main()
  File "/map-vepfs/taoran/graph_planner/scripts/eval_graphplanner_rllm.py", line 353, in main
    trainer.train()
  File "/map-vepfs/taoran/graph_planner/rllm/rllm/trainer/agent_trainer.py", line 80, in train
    ray.get(
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/worker.py", line 2858, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/map-vepfs/taoran/envs/taoran/lib/python3.10/site-packages/ray/_private/worker.py", line 958, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): [36mray::TaskRunner.run()[39m (pid=1680586, ip=192.168.0.70, actor_id=62d63a2586484fb984c17fe001000000, repr=<rllm.trainer.verl.train_agent_ppo.TaskRunner object at 0x7f15c567b1c0>)
  File "/map-vepfs/taoran/graph_planner/rllm/rllm/trainer/verl/train_agent_ppo.py", line 195, in run
    trainer = AgentPPOTrainer(
  File "/map-vepfs/taoran/graph_planner/rllm/rllm/trainer/verl/agent_ppo_trainer.py", line 50, in __init__
    super().__init__(config=config, tokenizer=tokenizer, role_worker_mapping=role_worker_mapping, resource_pool_manager=resource_pool_manager, ray_worker_group_cls=ray_worker_group_cls, reward_fn=reward_fn, val_reward_fn=val_reward_fn)
  File "/map-vepfs/taoran/graph_planner/rllm/verl/verl/trainer/ppo/ray_trainer.py", line 388, in __init__
    self._validate_config()
  File "/map-vepfs/taoran/graph_planner/rllm/verl/verl/trainer/ppo/ray_trainer.py", line 461, in _validate_config
    check_mutually_exclusive(
  File "/map-vepfs/taoran/graph_planner/rllm/verl/verl/trainer/ppo/ray_trainer.py", line 449, in check_mutually_exclusive
    raise ValueError(
ValueError: [actor_rollout_ref.actor] Please set at least one of 'actor_rollout_ref.actor.micro_batch_size' or 'actor_rollout_ref.actor.micro_batch_size_per_gpu'.
